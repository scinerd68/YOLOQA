{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-07-11T02:06:18.334790Z","iopub.status.busy":"2022-07-11T02:06:18.334406Z","iopub.status.idle":"2022-07-11T02:06:20.004800Z","shell.execute_reply":"2022-07-11T02:06:20.003995Z","shell.execute_reply.started":"2022-07-11T02:06:18.334711Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn.functional as F"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["device = \"cuda\" if torch.cuda.is_available() else 'cpu'"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-07-11T02:06:20.006853Z","iopub.status.busy":"2022-07-11T02:06:20.006344Z","iopub.status.idle":"2022-07-11T02:06:25.280598Z","shell.execute_reply":"2022-07-11T02:06:25.279560Z","shell.execute_reply.started":"2022-07-11T02:06:20.006799Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["d:\\ComputerScience\\BachKhoa\\ProjectII\\YOLOQA\\venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import torch.nn as nn\n","from transformers import AutoModelForTokenClassification\n","\n","\n","class QASpanDetector(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.model = AutoModelForTokenClassification.from_pretrained('roberta-base', num_labels=2)\n","        # self.model = AutoModelForTokenClassification.from_pretrained('YituTech/conv-bert-base', num_labels=2)\n","\n","    def forward(self, input_ids, attention_mask):\n","        outputs = self.model(input_ids=input_ids,\n","                             attention_mask=attention_mask)\n","        return outputs"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-07-11T02:06:25.282777Z","iopub.status.busy":"2022-07-11T02:06:25.282441Z","iopub.status.idle":"2022-07-11T02:06:33.727597Z","shell.execute_reply":"2022-07-11T02:06:33.726510Z","shell.execute_reply.started":"2022-07-11T02:06:25.282743Z"},"trusted":true},"outputs":[],"source":["# model = torch.load('../input/robertayolo/yolo_qa_v6.pth', map_location=torch.device('cpu'))\n","# model = torch.load('../input/robertayolo/yolo_qa_v6.pth')\n","# model = torch.load('../input/robertayolo/roberta_yolo_2_epochs.pth')\n","# model = torch.load('../input/xlmyoloqamodel/yolo_qa.pth')\n","# model = torch.load('../input/conv-bert-yolo-model/yolo_qa.pth')\n","# model = QASpanDetector()\n","model = torch.load('models/yolo_qa_v6.pth', map_location=torch.device(device))"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-07-11T02:06:33.729528Z","iopub.status.busy":"2022-07-11T02:06:33.729165Z","iopub.status.idle":"2022-07-11T02:06:34.135300Z","shell.execute_reply":"2022-07-11T02:06:34.134483Z","shell.execute_reply.started":"2022-07-11T02:06:33.729491Z"},"trusted":true},"outputs":[],"source":["from transformers.data.metrics.squad_metrics import compute_f1"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-07-11T02:06:34.137749Z","iopub.status.busy":"2022-07-11T02:06:34.137404Z","iopub.status.idle":"2022-07-11T02:06:34.149036Z","shell.execute_reply":"2022-07-11T02:06:34.148181Z","shell.execute_reply.started":"2022-07-11T02:06:34.137717Z"},"trusted":true},"outputs":[],"source":["import json\n","\n","class SquadDataset(torch.utils.data.Dataset):\n","    def __init__(self, file_path, tokenizer):\n","        with open(file_path, 'r') as f:\n","            self.data = json.load(f)\n","\n","        self.tokenizer = tokenizer\n","        self.contexts = []\n","        self.questions = []\n","        self.answers = []\n","        for group in self.data['data']:\n","            for passage in group['paragraphs']:\n","                context = passage['context']\n","                for qa in passage['qas']:\n","                    question = qa['question']\n","                    if len(qa['answers']) == 0:\n","                        continue\n","                    self.questions.append(question)\n","                    self.contexts.append(context)\n","                    answers = [answer['text'] for answer in qa['answers']]\n","                    self.answers.append(answers)\n","\n","    def __getitem__(self, index):\n","        context = self.contexts[index]\n","        question = self.questions[index]\n","        answer = self.answers[index]\n","\n","        encodings = self.tokenizer(context, question, truncation=True, padding=True)\n","        encodings = {key: torch.tensor(val) for key, val in encodings.items()}\n","        encodings['answers'] = answer\n","        encodings['question'] = question\n","        encodings['context'] = context\n","\n","        return encodings\n","\n","    def __len__(self):\n","        return len(self.questions)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-07-11T02:06:34.151549Z","iopub.status.busy":"2022-07-11T02:06:34.150341Z","iopub.status.idle":"2022-07-11T02:06:34.164159Z","shell.execute_reply":"2022-07-11T02:06:34.163254Z","shell.execute_reply.started":"2022-07-11T02:06:34.151521Z"},"trusted":true},"outputs":[],"source":["class CustomCollator:\n","    def __init__(self, tokenizer):\n","        self.pad_token_id = tokenizer.pad_token_id\n","\n","    def __call__(self, samples):\n","        batch_size = len(samples)\n","        assert batch_size == 1, f'Only batch_size=1 supported, got batch_size={batch_size}.'\n","\n","        sample = samples[0]\n","\n","        max_seq_length = tokenizer.model_max_length\n","        padded_length = max_seq_length\n","\n","        input_shape = (1, padded_length)\n","        input_ids = torch.full(input_shape,\n","                               self.pad_token_id,\n","                               dtype=torch.long)\n","        attention_mask = torch.zeros(input_shape, dtype=torch.long)\n","\n","        seq_length = len(sample['input_ids'])\n","        input_ids[0, :seq_length] = sample['input_ids']\n","        attention_mask[0, :seq_length] = sample['attention_mask']\n","\n","        return dict(input_ids=input_ids,\n","                    attention_mask=attention_mask,\n","                    answers=sample['answers'],\n","                    question=sample['question'],\n","                    context=sample['context'])"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-07-11T02:06:34.166071Z","iopub.status.busy":"2022-07-11T02:06:34.165675Z","iopub.status.idle":"2022-07-11T02:06:37.935777Z","shell.execute_reply":"2022-07-11T02:06:37.934993Z","shell.execute_reply.started":"2022-07-11T02:06:34.166037Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading: 100%|██████████| 481/481 [00:00<?, ?B/s] \n","Downloading: 100%|██████████| 878k/878k [01:22<00:00, 10.9kB/s] \n","Downloading: 100%|██████████| 446k/446k [00:10<00:00, 43.2kB/s] \n","Downloading: 100%|██████████| 1.29M/1.29M [00:36<00:00, 36.9kB/s]\n"]}],"source":["from transformers import AutoTokenizer\n","# tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n","tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n","# tokenizer = AutoTokenizer.from_pretrained(\"YituTech/conv-bert-base\")"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-07-11T02:06:37.937354Z","iopub.status.busy":"2022-07-11T02:06:37.936892Z","iopub.status.idle":"2022-07-11T02:06:38.062687Z","shell.execute_reply":"2022-07-11T02:06:38.061893Z","shell.execute_reply.started":"2022-07-11T02:06:37.937306Z"},"trusted":true},"outputs":[],"source":["dev_data = SquadDataset('data/dev-v2.0.json', tokenizer)\n","# dev_data = SquadDataset('../input/squad-20/train-v2.0.json', tokenizer)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-07-11T02:06:38.064398Z","iopub.status.busy":"2022-07-11T02:06:38.064043Z","iopub.status.idle":"2022-07-11T02:06:38.069493Z","shell.execute_reply":"2022-07-11T02:06:38.068747Z","shell.execute_reply.started":"2022-07-11T02:06:38.064363Z"},"trusted":true},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","collate = CustomCollator(tokenizer)\n","dev_loader = DataLoader(dev_data,\n","                      batch_size=1,\n","                      shuffle=False,\n","                      collate_fn=collate)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2022-07-11T02:06:38.071508Z","iopub.status.busy":"2022-07-11T02:06:38.070885Z","iopub.status.idle":"2022-07-11T02:06:38.105503Z","shell.execute_reply":"2022-07-11T02:06:38.104769Z","shell.execute_reply.started":"2022-07-11T02:06:38.071471Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'input_ids': tensor([[    0,   133, 20336,  1253,    36,   487, 16803,    35,   234,  2126,\n","            119,  8771,   131,  1515,    35, 20336,  8771,   131,  5862,    35,\n","          20336, 28867,    43,    58,     5,    82,    54,    11,     5,   158,\n","            212,     8,   365,   212, 11505,   851,    49,   766,     7, 37741,\n","              6,    10,   976,    11,  1470,     4,   252,    58, 22306,    31,\n","          41498,  6697,   487, 16803,   113,   606,    31,    22,   487, 27209,\n","            397,  8070, 10369,   268,     8, 34941,    31, 10060,     6, 14605,\n","              8,  8683,    54,     6,   223,    49,   884, 13065,   139,     6,\n","           1507,     7, 24909, 10668, 12107,     7,  1745,  3163,  6395,     9,\n","            580, 17932,   493,     4,  6278,  6808,     9,  8446, 43616,     8,\n","          17793,    19,     5,  3763,  3848,  1173,     8,  7733,    12,   534,\n","           6695,  1173,  9883,     6,    49, 29285,    74,  9097, 19388,    19,\n","              5,  9347,   154,   811,    12,   805, 13426,     9,   580, 17932,\n","            493,     4,    20, 11693,  4106,     8,  7289,  3599,     9,     5,\n","          20336,  1253,  4373,  3225,    11,     5,    78,   457,     9,     5,\n","            158,   212,  3220,     6,     8,    24,  1143,     7, 14842,    81,\n","              5, 27544, 11505,     4,     2,     2,  1121,    99,   247,    16,\n","          37741,  2034,   116,     2,     1,     1,     1,     1,     1,     1,\n","              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","              1,     1]]),\n"," 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0]]),\n"," 'answers': ['France', 'France', 'France', 'France'],\n"," 'question': 'In what country is Normandy located?',\n"," 'context': 'The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.'}"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["next(iter(dev_loader))"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2022-07-11T02:06:38.108152Z","iopub.status.busy":"2022-07-11T02:06:38.107765Z","iopub.status.idle":"2022-07-11T02:06:38.115654Z","shell.execute_reply":"2022-07-11T02:06:38.114904Z","shell.execute_reply.started":"2022-07-11T02:06:38.108115Z"},"trusted":true},"outputs":[{"data":{"text/plain":["512"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.model_max_length"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2022-07-11T02:06:38.117461Z","iopub.status.busy":"2022-07-11T02:06:38.116974Z","iopub.status.idle":"2022-07-11T02:06:43.925613Z","shell.execute_reply":"2022-07-11T02:06:43.924648Z","shell.execute_reply.started":"2022-07-11T02:06:38.117424Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["############Evaluate############\n","Average F1: 1.0\n"]}],"source":["import csv\n","\n","device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n","\n","model.eval()\n","f1 = 0\n","num_examples = 0\n","\n","# open the file in the write mode\n","f = open('results.csv', 'w')\n","writer = csv.writer(f)\n","writer.writerow(['Question', 'Context', 'Ground Truth', 'Prediction', 'F1'])\n","\n","print(\"############Evaluate############\")\n","with torch.no_grad():\n","    for batch_idx, batch in enumerate(dev_loader):\n","        sentence_length = batch['input_ids'].size(1)\n","        batch_size = batch['input_ids'].size(0)\n","\n","        outputs = model(batch['input_ids'].to(device), batch['attention_mask'].to(device))\n","        obj_pred = outputs['logits'][0, :, 0]\n","        answer_start_pred = int(torch.argmax(obj_pred))\n","        answer_length_pred = int(outputs['logits'][0, :, 1][answer_start_pred].exp().round())\n","        answer_pred = tokenizer.decode(batch['input_ids'][0, answer_start_pred:answer_start_pred+answer_length_pred],\n","                                      skip_special_tokens=True)\n","        \n","        answers = batch['answers']\n","        max_f1 = 0\n","        best_fit_target = ''\n","        for answer_target in answers:\n","            f1_score = compute_f1(answer_target, answer_pred)\n","            if f1_score >= max_f1:\n","                max_f1 = f1_score\n","                best_fit_target = answer_target\n","        writer.writerow([batch['question'], batch['context'], best_fit_target, answer_pred, max_f1])\n","\n","        f1 += max_f1\n","        num_examples += 1\n","\n","print('Average F1:', f1 / num_examples)\n","f.close()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.7.9 ('venv': venv)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"vscode":{"interpreter":{"hash":"6c339cff43c8d90d763d7e0dd4f078628a199cc2901cfbf33671f69986c16de1"}}},"nbformat":4,"nbformat_minor":4}
